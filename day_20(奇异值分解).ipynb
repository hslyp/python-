{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc03aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始矩阵 A:\n",
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]\n",
      " [13 14 15]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9],\n",
    "              [10, 11, 12],\n",
    "              [13, 14, 15]])\n",
    "print(\"原始矩阵 A:\")\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72a4f2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "奇异值 sigma:\n",
      "[3.51826483e+01 1.47690770e+00 3.74442300e-16]\n"
     ]
    }
   ],
   "source": [
    "# 进行 SVD 分解\n",
    "U, sigma, Vt = np.linalg.svd(A, full_matrices=False)\n",
    "print(\"\\n奇异值 sigma:\")\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c54f58cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "保留前 1 个奇异值后的近似矩阵 A_approx:\n",
      "[[ 1.85152908  2.05208851  2.25264793]\n",
      " [ 4.5411984   5.03310541  5.52501242]\n",
      " [ 7.23086771  8.01412231  8.7973769 ]\n",
      " [ 9.92053702 10.99513921 12.06974139]\n",
      " [12.61020633 13.9761561  15.34210588]]\n",
      "\n",
      "近似误差 (Frobenius 范数相对误差): 0.04194136031471535\n"
     ]
    }
   ],
   "source": [
    "# 保留前 k=1 个奇异值进行降维\n",
    "k = 1\n",
    "U_k = U[:, :k]  # 取 U 的前 k 列，因为要保持行数不变\n",
    "sigma_k = sigma[:k]  # 取前 k 个奇异值\n",
    "Vt_k = Vt[:k, :]  # 取 Vt 的前 k 行，因为要保持列数不变\n",
    "\n",
    "# 近似重构矩阵 A,常用于信号or图像筛除噪声\n",
    "A_approx = U_k @ np.diag(sigma_k) @ Vt_k\n",
    "print(\"\\n保留前\", k, \"个奇异值后的近似矩阵 A_approx:\")\n",
    "print(A_approx)\n",
    "\n",
    "# 计算近似误差\n",
    "error = np.linalg.norm(A - A_approx, 'fro') / np.linalg.norm(A, 'fro')\n",
    "print(\"\\n近似误差 (Frobenius 范数相对误差):\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a097b257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\vs\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集形状: (800, 50)\n",
      "测试集形状: (200, 50)\n",
      "Vt_train 矩阵形状: (50, 50)\n",
      "保留 k=10 后的 Vt_k 矩阵形状: (10, 50)\n",
      "降维后训练集形状: (800, 10)\n",
      "降维后测试集形状: (200, 10)\n",
      "测试集准确率: 0.595\n",
      "训练集近似误差 (Frobenius 范数相对误差): 0.852479929511559\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 设置随机种子以便结果可重复\n",
    "np.random.seed(42)\n",
    "\n",
    "# 模拟数据：1000 个样本，50 个特征\n",
    "n_samples = 1000\n",
    "n_features = 50\n",
    "X = np.random.randn(n_samples, n_features) * 10  # 随机生成特征数据\n",
    "y = (X[:, 0] + X[:, 1] > 0).astype(int)  # 模拟二分类标签\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"训练集形状: {X_train.shape}\")\n",
    "print(f\"测试集形状: {X_test.shape}\")\n",
    "\n",
    "# 对训练集进行 SVD 分解\n",
    "U_train, sigma_train, Vt_train = np.linalg.svd(X_train, full_matrices=False)\n",
    "print(f\"Vt_train 矩阵形状: {Vt_train.shape}\")\n",
    "\n",
    "# 选择保留的奇异值数量 k\n",
    "k = 10\n",
    "Vt_k = Vt_train[:k, :]  # 保留前 k 行，形状为 (k, 50)\n",
    "print(f\"保留 k={k} 后的 Vt_k 矩阵形状: {Vt_k.shape}\")\n",
    "\n",
    "# 降维训练集：X_train_reduced = X_train @ Vt_k.T\n",
    "X_train_reduced = X_train @ Vt_k.T\n",
    "print(f\"降维后训练集形状: {X_train_reduced.shape}\")\n",
    "\n",
    "# 使用相同的 Vt_k 对测试集进行降维：X_test_reduced = X_test @ Vt_k.T\n",
    "X_test_reduced = X_test @ Vt_k.T\n",
    "print(f\"降维后测试集形状: {X_test_reduced.shape}\")\n",
    "\n",
    "# 训练模型（以逻辑回归为例）\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train_reduced, y_train)\n",
    "\n",
    "# 预测并评估\n",
    "y_pred = model.predict(X_test_reduced)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"测试集准确率: {accuracy}\")\n",
    "\n",
    "# 计算训练集的近似误差（可选，仅用于评估降维效果）\n",
    "X_train_approx = U_train[:, :k] @ np.diag(sigma_train[:k]) @ Vt_k\n",
    "error = np.linalg.norm(X_train - X_train_approx, 'fro') / np.linalg.norm(X_train, 'fro')\n",
    "print(f\"训练集近似误差 (Frobenius 范数相对误差): {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e208fb16",
   "metadata": {},
   "source": [
    "### 6. 实际操作中的注意事项\n",
    "1. **标准化数据**：在进行 SVD 之前，通常需要对数据进行标准化（均值为 0，方差为 1），以避免某些特征的量纲差异对降维结果的影响。可以使用 `sklearn.preprocessing.StandardScaler`。\n",
    "   ```python\n",
    "   from sklearn.preprocessing import StandardScaler\n",
    "   scaler = StandardScaler()\n",
    "   X_train_scaled = scaler.fit_transform(X_train)\n",
    "   X_test_scaled = scaler.transform(X_test)\n",
    "   ```\n",
    "   注意：`scaler` 必须在训练集上 `fit`，然后对测试集只用 `transform`，以避免数据泄漏。\n",
    "\n",
    "2. **选择合适的 $k$**：可以通过累计方差贡献率（explained variance ratio）选择 $k$，通常选择解释 90%-95% 方差的 $k$ 值。代码中可以计算：\n",
    "   ```python\n",
    "   explained_variance_ratio = np.cumsum(sigma_train**2) / np.sum(sigma_train**2)\n",
    "   print(f\"前 {k} 个奇异值的累计方差贡献率: {explained_variance_ratio[k-1]}\")\n",
    "   ```\n",
    "\n",
    "3. **使用 sklearn 的 TruncatedSVD**：`sklearn` 提供了 `TruncatedSVD` 类，专门用于高效降维，尤其适合大规模数据。它直接计算前 $k$ 个奇异值和向量，避免完整 SVD 的计算开销。\n",
    "   ```python\n",
    "   from sklearn.decomposition import TruncatedSVD\n",
    "   svd = TruncatedSVD(n_components=k, random_state=42)\n",
    "   X_train_reduced = svd.fit_transform(X_train)\n",
    "   X_test_reduced = svd.transform(X_test)\n",
    "   print(f\"累计方差贡献率: {sum(svd.explained_variance_ratio_)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
