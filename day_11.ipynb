{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e8091b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd    #用于数据处理和分析，可处理表格数据。\n",
    "import numpy as np     #用于数值计算，提供了高效的数组操作。\n",
    "import matplotlib.pyplot as plt    #用于绘制各种类型的图表\n",
    "import seaborn as sns   #基于matplotlib的高级绘图库，能绘制更美观的统计图形。\n",
    " \n",
    " # 设置中文字体（解决中文显示问题）\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # Windows系统常用黑体字体\n",
    "plt.rcParams['axes.unicode_minus'] = False    # 正常显示负号\n",
    "data = pd.read_csv('data.csv')    #读取数据\n",
    "\n",
    "# 先筛选字符串变量 \n",
    "discrete_features = data.select_dtypes(include=['object']).columns.tolist()\n",
    "# Home Ownership 标签编码\n",
    "home_ownership_mapping = {\n",
    "    'Own Home': 1,\n",
    "    'Rent': 2,\n",
    "    'Have Mortgage': 3,\n",
    "    'Home Mortgage': 4\n",
    "}\n",
    "data['Home Ownership'] = data['Home Ownership'].map(home_ownership_mapping)\n",
    "\n",
    "# Years in current job 标签编码\n",
    "years_in_job_mapping = {\n",
    "    '< 1 year': 1,\n",
    "    '1 year': 2,\n",
    "    '2 years': 3,\n",
    "    '3 years': 4,\n",
    "    '4 years': 5,\n",
    "    '5 years': 6,\n",
    "    '6 years': 7,\n",
    "    '7 years': 8,\n",
    "    '8 years': 9,\n",
    "    '9 years': 10,\n",
    "    '10+ years': 11\n",
    "}\n",
    "data['Years in current job'] = data['Years in current job'].map(years_in_job_mapping)\n",
    "\n",
    "# Purpose 独热编码，记得需要将bool类型转换为数值\n",
    "data = pd.get_dummies(data, columns=['Purpose'])\n",
    "data2 = pd.read_csv(\"data.csv\") # 重新读取数据，用来做列名对比\n",
    "list_final = [] # 新建一个空列表，用于存放独热编码后新增的特征名\n",
    "for i in data.columns:\n",
    "    if i not in data2.columns:\n",
    "       list_final.append(i) # 这里打印出来的就是独热编码后的特征名\n",
    "for i in list_final:\n",
    "    data[i] = data[i].astype(int) # 这里的i就是独热编码后的特征名\n",
    "\n",
    "\n",
    "\n",
    "# Term 0 - 1 映射\n",
    "term_mapping = {\n",
    "    'Short Term': 0,\n",
    "    'Long Term': 1\n",
    "}\n",
    "data['Term'] = data['Term'].map(term_mapping)\n",
    "data.rename(columns={'Term': 'Long Term'}, inplace=True) # 重命名列\n",
    "continuous_features = data.select_dtypes(include=['int64', 'float64']).columns.tolist()  #把筛选出来的列名转换成列表\n",
    " \n",
    " # 连续特征用中位数补全\n",
    "for feature in continuous_features:     \n",
    "    mode_value = data[feature].mode()[0]            #获取该列的众数。\n",
    "    data[feature].fillna(mode_value, inplace=True)          #用众数填充该列的缺失值，inplace=True表示直接在原数据上修改。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14baf28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集、验证集和测试集，因为需要考2次\n",
    "# 这里演示一下如何2次划分数据集，因为这个函数只能划分一次，所以需要调用两次才能划分出训练集、验证集和测试集。\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop(['Credit Default'], axis=1)  # 特征，axis=1表示按列删除\n",
    "y = data['Credit Default']  # 标签\n",
    "# 按照8:1:1划分训练集、验证集和测试集\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)  # 80%训练集，20%临时集\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 50%验证集，50%测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28dfce96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:\n",
      "X_train: (6000, 31)\n",
      "y_train: (6000,)\n",
      "X_val: (750, 31)\n",
      "y_val: (750,)\n",
      "X_test: (750, 31)\n",
      "y_test: (750,)\n"
     ]
    }
   ],
   "source": [
    "# X_train, y_train (80%)\n",
    "# X_val, y_val (10%)\n",
    "# X_test, y_test (10%)\n",
    "\n",
    "print(\"Data shapes:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_val:\", X_val.shape)\n",
    "print(\"y_val:\", y_val.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c73d6263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最开始也说了 很多调参函数自带交叉验证，甚至是必选的参数，你如果想要不交叉反而实现起来会麻烦很多\n",
    "# 所以这里我们还是只划分一次数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop(['Credit Default'], axis=1)  # 特征，axis=1表示按列删除\n",
    "y = data['Credit Default'] # 标签\n",
    "# 按照8:2划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 80%训练集，20%测试集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c542a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier #随机森林分类器\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score # 用于评估分类器性能的指标\n",
    "from sklearn.metrics import classification_report, confusion_matrix #用于生成分类报告和混淆矩阵\n",
    "import warnings #用于忽略警告信息\n",
    "warnings.filterwarnings(\"ignore\") # 忽略所有警告信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b760066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. 默认参数随机森林 (训练集 -> 测试集) ---\n",
      "训练与预测耗时: 0.9094 秒\n",
      "\n",
      "默认随机森林 在测试集上的分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.97      0.86      1059\n",
      "           1       0.79      0.30      0.43       441\n",
      "\n",
      "    accuracy                           0.77      1500\n",
      "   macro avg       0.78      0.63      0.64      1500\n",
      "weighted avg       0.77      0.77      0.73      1500\n",
      "\n",
      "默认随机森林 在测试集上的混淆矩阵：\n",
      "[[1023   36]\n",
      " [ 309  132]]\n"
     ]
    }
   ],
   "source": [
    "# --- 1. 默认参数的随机森林 ---\n",
    "# 评估基准模型，这里确实不需要验证集\n",
    "print(\"--- 1. 默认参数随机森林 (训练集 -> 测试集) ---\")\n",
    "import time # 这里介绍一个新的库，time库，主要用于时间相关的操作，因为调参需要很长时间，记录下会帮助后人知道大概的时长\n",
    "start_time = time.time() # 记录开始时间\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train) # 在训练集上训练\n",
    "rf_pred = rf_model.predict(X_test) # 在测试集上预测\n",
    "end_time = time.time() # 记录结束时间\n",
    "\n",
    "print(f\"训练与预测耗时: {end_time - start_time:.4f} 秒\")\n",
    "print(\"\\n默认随机森林 在测试集上的分类报告：\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "print(\"默认随机森林 在测试集上的混淆矩阵：\")\n",
    "print(confusion_matrix(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "915f5c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. 网格搜索优化随机森林 (训练集 -> 测试集) ---\n",
      "网格搜索耗时: 36.9344 秒\n",
      "最佳参数:  {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "网格搜索优化后的随机森林 在测试集上的分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.97      0.86      1059\n",
      "           1       0.80      0.28      0.42       441\n",
      "\n",
      "    accuracy                           0.77      1500\n",
      "   macro avg       0.78      0.63      0.64      1500\n",
      "weighted avg       0.77      0.77      0.73      1500\n",
      "\n",
      "网格搜索优化后的随机森林 在测试集上的混淆矩阵：\n",
      "[[1028   31]\n",
      " [ 317  124]]\n"
     ]
    }
   ],
   "source": [
    "# --- 2. 网格搜索优化随机森林 ---\n",
    "print(\"\\n--- 2. 网格搜索优化随机森林 (训练集 -> 测试集) ---\")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 定义要搜索的参数网格\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# 创建网格搜索对象\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), # 随机森林分类器\n",
    "                           param_grid=param_grid, # 参数网格\n",
    "                           cv=5, # 5折交叉验证\n",
    "                           n_jobs=-1, # 使用所有可用的CPU核心进行并行计算\n",
    "                           scoring='accuracy') # 使用准确率作为评分标准\n",
    "\n",
    "start_time = time.time()\n",
    "# 在训练集上进行网格搜索\n",
    "grid_search.fit(X_train, y_train) # 在训练集上训练，模型实例化和训练的方法都被封装在这个网格搜索对象里了\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"网格搜索耗时: {end_time - start_time:.4f} 秒\")\n",
    "print(\"最佳参数: \", grid_search.best_params_) #best_params_属性返回最佳参数组合\n",
    "\n",
    "# 使用最佳参数的模型进行预测\n",
    "best_model = grid_search.best_estimator_ # 获取最佳模型\n",
    "best_pred = best_model.predict(X_test) # 在测试集上进行预测\n",
    "\n",
    "print(\"\\n网格搜索优化后的随机森林 在测试集上的分类报告：\")\n",
    "print(classification_report(y_test, best_pred))\n",
    "print(\"网格搜索优化后的随机森林 在测试集上的混淆矩阵：\")\n",
    "print(confusion_matrix(y_test, best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d79586ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. 贝叶斯优化随机森林 (训练集 -> 测试集) ---\n",
      "贝叶斯优化耗时: 35.9038 秒\n",
      "最佳参数:  OrderedDict([('max_depth', 23), ('min_samples_leaf', 3), ('min_samples_split', 4), ('n_estimators', 82)])\n",
      "\n",
      "贝叶斯优化后的随机森林 在测试集上的分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.97      0.85      1059\n",
      "           1       0.78      0.29      0.42       441\n",
      "\n",
      "    accuracy                           0.77      1500\n",
      "   macro avg       0.77      0.63      0.64      1500\n",
      "weighted avg       0.77      0.77      0.73      1500\n",
      "\n",
      "贝叶斯优化后的随机森林 在测试集上的混淆矩阵：\n",
      "[[1024   35]\n",
      " [ 314  127]]\n"
     ]
    }
   ],
   "source": [
    "# --- 2. 贝叶斯优化随机森林 ---\n",
    "print(\"\\n--- 2. 贝叶斯优化随机森林 (训练集 -> 测试集) ---\")\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time\n",
    "\n",
    "# 定义要搜索的参数空间\n",
    "search_space = {\n",
    "    'n_estimators': Integer(50, 200),\n",
    "    'max_depth': Integer(10, 30),\n",
    "    'min_samples_split': Integer(2, 10),\n",
    "    'min_samples_leaf': Integer(1, 4)\n",
    "}\n",
    "\n",
    "# 创建贝叶斯优化搜索对象\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    search_spaces=search_space,\n",
    "    n_iter=32,  # 迭代次数，可根据需要调整\n",
    "    cv=5, # 5折交叉验证，这个参数是必须的，不能设置为1，否则就是在训练集上做预测了\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "# 在训练集上进行贝叶斯优化搜索\n",
    "bayes_search.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"贝叶斯优化耗时: {end_time - start_time:.4f} 秒\")\n",
    "print(\"最佳参数: \", bayes_search.best_params_)\n",
    "\n",
    "# 使用最佳参数的模型进行预测\n",
    "best_model = bayes_search.best_estimator_\n",
    "best_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n贝叶斯优化后的随机森林 在测试集上的分类报告：\")\n",
    "print(classification_report(y_test, best_pred))\n",
    "print(\"贝叶斯优化后的随机森林 在测试集上的混淆矩阵：\")\n",
    "print(confusion_matrix(y_test, best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8bc4dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. 贝叶斯优化随机森林 (训练集 -> 测试集) ---\n",
      "|   iter    |  target   | max_depth | min_sa... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.7828   \u001b[39m | \u001b[39m17.49    \u001b[39m | \u001b[39m3.852    \u001b[39m | \u001b[39m7.856    \u001b[39m | \u001b[39m139.8    \u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.78     \u001b[39m | \u001b[39m13.12    \u001b[39m | \u001b[39m1.468    \u001b[39m | \u001b[39m2.465    \u001b[39m | \u001b[39m179.9    \u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.7817   \u001b[39m | \u001b[39m22.02    \u001b[39m | \u001b[39m3.124    \u001b[39m | \u001b[39m2.165    \u001b[39m | \u001b[39m195.5    \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.7825   \u001b[39m | \u001b[39m26.65    \u001b[39m | \u001b[39m1.637    \u001b[39m | \u001b[39m3.455    \u001b[39m | \u001b[39m77.51    \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.7822   \u001b[39m | \u001b[39m16.08    \u001b[39m | \u001b[39m2.574    \u001b[39m | \u001b[39m5.456    \u001b[39m | \u001b[39m93.68    \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.7803   \u001b[39m | \u001b[39m17.93    \u001b[39m | \u001b[39m3.082    \u001b[39m | \u001b[39m5.915    \u001b[39m | \u001b[39m126.9    \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.7772   \u001b[39m | \u001b[39m10.98    \u001b[39m | \u001b[39m1.055    \u001b[39m | \u001b[39m6.804    \u001b[39m | \u001b[39m158.6    \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.7765   \u001b[39m | \u001b[39m10.09    \u001b[39m | \u001b[39m1.121    \u001b[39m | \u001b[39m5.732    \u001b[39m | \u001b[39m102.8    \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.78     \u001b[39m | \u001b[39m29.42    \u001b[39m | \u001b[39m3.129    \u001b[39m | \u001b[39m9.951    \u001b[39m | \u001b[39m106.1    \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.7822   \u001b[39m | \u001b[39m19.43    \u001b[39m | \u001b[39m1.481    \u001b[39m | \u001b[39m8.416    \u001b[39m | \u001b[39m64.48    \u001b[39m |\n",
      "| \u001b[35m11       \u001b[39m | \u001b[35m0.783    \u001b[39m | \u001b[35m28.77    \u001b[39m | \u001b[35m3.119    \u001b[39m | \u001b[35m5.601    \u001b[39m | \u001b[35m199.8    \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.7798   \u001b[39m | \u001b[39m26.76    \u001b[39m | \u001b[39m2.866    \u001b[39m | \u001b[39m4.587    \u001b[39m | \u001b[39m197.0    \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.78     \u001b[39m | \u001b[39m13.87    \u001b[39m | \u001b[39m2.864    \u001b[39m | \u001b[39m3.986    \u001b[39m | \u001b[39m165.2    \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.7782   \u001b[39m | \u001b[39m10.13    \u001b[39m | \u001b[39m2.378    \u001b[39m | \u001b[39m9.813    \u001b[39m | \u001b[39m129.0    \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.7787   \u001b[39m | \u001b[39m24.85    \u001b[39m | \u001b[39m2.575    \u001b[39m | \u001b[39m4.403    \u001b[39m | \u001b[39m52.95    \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.78     \u001b[39m | \u001b[39m27.74    \u001b[39m | \u001b[39m2.593    \u001b[39m | \u001b[39m4.055    \u001b[39m | \u001b[39m129.7    \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m0.7805   \u001b[39m | \u001b[39m14.12    \u001b[39m | \u001b[39m3.91     \u001b[39m | \u001b[39m2.115    \u001b[39m | \u001b[39m60.42    \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m0.7827   \u001b[39m | \u001b[39m18.97    \u001b[39m | \u001b[39m1.264    \u001b[39m | \u001b[39m2.414    \u001b[39m | \u001b[39m175.5    \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m0.7765   \u001b[39m | \u001b[39m11.66    \u001b[39m | \u001b[39m3.395    \u001b[39m | \u001b[39m9.376    \u001b[39m | \u001b[39m195.7    \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m0.7793   \u001b[39m | \u001b[39m17.29    \u001b[39m | \u001b[39m1.86     \u001b[39m | \u001b[39m7.538    \u001b[39m | \u001b[39m150.1    \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m0.7822   \u001b[39m | \u001b[39m19.36    \u001b[39m | \u001b[39m1.97     \u001b[39m | \u001b[39m8.328    \u001b[39m | \u001b[39m64.46    \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m0.781    \u001b[39m | \u001b[39m29.96    \u001b[39m | \u001b[39m3.562    \u001b[39m | \u001b[39m7.921    \u001b[39m | \u001b[39m199.0    \u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m0.7808   \u001b[39m | \u001b[39m18.14    \u001b[39m | \u001b[39m2.653    \u001b[39m | \u001b[39m5.696    \u001b[39m | \u001b[39m138.2    \u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m0.7818   \u001b[39m | \u001b[39m15.49    \u001b[39m | \u001b[39m3.068    \u001b[39m | \u001b[39m9.806    \u001b[39m | \u001b[39m140.5    \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m0.781    \u001b[39m | \u001b[39m19.36    \u001b[39m | \u001b[39m3.244    \u001b[39m | \u001b[39m9.495    \u001b[39m | \u001b[39m141.0    \u001b[39m |\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m0.7808   \u001b[39m | \u001b[39m21.09    \u001b[39m | \u001b[39m2.187    \u001b[39m | \u001b[39m4.491    \u001b[39m | \u001b[39m174.4    \u001b[39m |\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m0.7795   \u001b[39m | \u001b[39m14.4     \u001b[39m | \u001b[39m3.276    \u001b[39m | \u001b[39m6.276    \u001b[39m | \u001b[39m141.1    \u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m0.7813   \u001b[39m | \u001b[39m16.64    \u001b[39m | \u001b[39m2.866    \u001b[39m | \u001b[39m2.51     \u001b[39m | \u001b[39m175.8    \u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m0.7793   \u001b[39m | \u001b[39m28.99    \u001b[39m | \u001b[39m1.05     \u001b[39m | \u001b[39m4.297    \u001b[39m | \u001b[39m199.6    \u001b[39m |\n",
      "| \u001b[35m30       \u001b[39m | \u001b[35m0.7837   \u001b[39m | \u001b[35m17.5     \u001b[39m | \u001b[35m2.553    \u001b[39m | \u001b[35m8.927    \u001b[39m | \u001b[35m138.6    \u001b[39m |\n",
      "| \u001b[39m31       \u001b[39m | \u001b[39m0.7795   \u001b[39m | \u001b[39m16.56    \u001b[39m | \u001b[39m3.761    \u001b[39m | \u001b[39m9.857    \u001b[39m | \u001b[39m137.2    \u001b[39m |\n",
      "| \u001b[39m32       \u001b[39m | \u001b[39m0.7793   \u001b[39m | \u001b[39m17.35    \u001b[39m | \u001b[39m1.551    \u001b[39m | \u001b[39m8.439    \u001b[39m | \u001b[39m138.9    \u001b[39m |\n",
      "| \u001b[39m33       \u001b[39m | \u001b[39m0.7798   \u001b[39m | \u001b[39m17.38    \u001b[39m | \u001b[39m3.878    \u001b[39m | \u001b[39m8.473    \u001b[39m | \u001b[39m139.3    \u001b[39m |\n",
      "| \u001b[39m34       \u001b[39m | \u001b[39m0.779    \u001b[39m | \u001b[39m24.33    \u001b[39m | \u001b[39m1.157    \u001b[39m | \u001b[39m5.795    \u001b[39m | \u001b[39m76.37    \u001b[39m |\n",
      "| \u001b[39m35       \u001b[39m | \u001b[39m0.7825   \u001b[39m | \u001b[39m26.71    \u001b[39m | \u001b[39m1.621    \u001b[39m | \u001b[39m3.293    \u001b[39m | \u001b[39m77.47    \u001b[39m |\n",
      "| \u001b[39m36       \u001b[39m | \u001b[39m0.7825   \u001b[39m | \u001b[39m29.04    \u001b[39m | \u001b[39m3.905    \u001b[39m | \u001b[39m5.19     \u001b[39m | \u001b[39m199.9    \u001b[39m |\n",
      "| \u001b[39m37       \u001b[39m | \u001b[39m0.7825   \u001b[39m | \u001b[39m18.26    \u001b[39m | \u001b[39m2.861    \u001b[39m | \u001b[39m9.151    \u001b[39m | \u001b[39m138.7    \u001b[39m |\n",
      "=========================================================================\n",
      "贝叶斯优化耗时: 128.9306 秒\n",
      "最佳参数:  {'max_depth': 17.502236740620297, 'min_samples_leaf': 2.5533082077180316, 'min_samples_split': 8.926771812562555, 'n_estimators': 138.5566475443472}\n",
      "\n",
      "贝叶斯优化后的随机森林 在测试集上的分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86      1059\n",
      "           1       0.83      0.26      0.40       441\n",
      "\n",
      "    accuracy                           0.77      1500\n",
      "   macro avg       0.79      0.62      0.63      1500\n",
      "weighted avg       0.78      0.77      0.72      1500\n",
      "\n",
      "贝叶斯优化后的随机森林 在测试集上的混淆矩阵：\n"
     ]
    }
   ],
   "source": [
    "# --- 2. 贝叶斯优化随机森林 ---\n",
    "print(\"\\n--- 2. 贝叶斯优化随机森林 (训练集 -> 测试集) ---\")\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# 假设 X_train, y_train, X_test, y_test 已经定义好\n",
    "# 定义目标函数，这里使用交叉验证来评估模型性能\n",
    "def rf_eval(n_estimators, max_depth, min_samples_split, min_samples_leaf):\n",
    "    n_estimators = int(n_estimators)\n",
    "    max_depth = int(max_depth)\n",
    "    min_samples_split = int(min_samples_split)\n",
    "    min_samples_leaf = int(min_samples_leaf)\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    return np.mean(scores)\n",
    "\n",
    "# 定义要搜索的参数空间\n",
    "pbounds_rf = {\n",
    "    'n_estimators': (50, 200),\n",
    "   'max_depth': (10, 30),\n",
    "   'min_samples_split': (2, 10),\n",
    "   'min_samples_leaf': (1, 4)\n",
    "}\n",
    "\n",
    "# 创建贝叶斯优化对象，设置 verbose=2 显示详细迭代信息\n",
    "optimizer_rf = BayesianOptimization(\n",
    "    f=rf_eval, # 目标函数\n",
    "    pbounds=pbounds_rf, # 参数空间\n",
    "    random_state=42, # 随机种子\n",
    "    verbose=2  # 显示详细迭代信息\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "# 开始贝叶斯优化\n",
    "optimizer_rf.maximize(\n",
    "    init_points=5,  # 初始随机采样点数\n",
    "    n_iter=32  # 迭代次数\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"贝叶斯优化耗时: {end_time - start_time:.4f} 秒\")\n",
    "print(\"最佳参数: \", optimizer_rf.max['params'])\n",
    "\n",
    "# 使用最佳参数的模型进行预测\n",
    "best_params = optimizer_rf.max['params']\n",
    "best_model = RandomForestClassifier(\n",
    "    n_estimators=int(best_params['n_estimators']),\n",
    "    max_depth=int(best_params['max_depth']),\n",
    "    min_samples_split=int(best_params['min_samples_split']),\n",
    "    min_samples_leaf=int(best_params['min_samples_leaf']),\n",
    "    random_state=42\n",
    ")\n",
    "best_model.fit(X_train, y_train)\n",
    "best_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n贝叶斯优化后的随机森林 在测试集上的分类报告：\")\n",
    "print(classification_report(y_test, best_pred))\n",
    "print(\"贝叶斯优化后的随机森林 在测试集上的混淆矩阵：\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
